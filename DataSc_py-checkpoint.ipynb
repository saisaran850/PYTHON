{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7afa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import WebCrawler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitters import CharacterTextSplitter\n",
    "\n",
    "class ResearchAgent:\n",
    "    def __init__(self, keywords):\n",
    "        self.keywords = keywords\n",
    "        self.crawler = WebCrawler()\n",
    "        self.text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        self.extractor = LangChainExtractor()\n",
    "\n",
    "    def crawl_and_extract_data(self, search_query):\n",
    "        raw_data = self.crawler.search_web(search_query)\n",
    "        filtered_data = self.filter_data(raw_data)\n",
    "        structured_data = self.extract_information(filtered_data)\n",
    "        return structured_data\n",
    "\n",
    "    def filter_data(self, raw_data):\n",
    "        # Filter based on keywords, relevance, or content type.\n",
    "        filtered = [entry for entry in raw_data if any(keyword in entry for keyword in self.keywords)]\n",
    "        return filtered\n",
    "\n",
    "    def extract_information(self, filtered_data):\n",
    "        # Extract and structure data using LangChain and LangGraph techniques\n",
    "        structured_data = []\n",
    "        for text in filtered_data:\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            structured_data.append(chunks)\n",
    "        return structured_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langgraph import LangGraph\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "class AnswerDraftingAgent:\n",
    "    def __init__(self):\n",
    "        self.llm = OpenAI(temperature=0.7)\n",
    "        self.graph = LangGraph()\n",
    "        self.answer_generator = LLMChain(llm=self.llm, prompt=PromptTemplate.from_template(\"Answer based\n",
    "                                                                                           \"on the following information\":\n",
    "                                                                                           {\"context\"}\"))\n",
    "\n",
    "    def aggregate_data_into_graph(self, structured_data):\n",
    "        # Create a knowledge graph based on the structured data from the Research Agent.\n",
    "        for data in structured_data:\n",
    "            # Example: Create nodes from structured data (facts, figures, etc.)\n",
    "            for chunk in data:\n",
    "                self.graph.add_node(chunk)\n",
    "                \n",
    "    def generate_answer(self, query):\n",
    "        # Use LangGraph to query the knowledge graph and generate a relevant answer\n",
    "        context = self.graph.query(query)\n",
    "        answer = self.answer_generator.run(context=context)\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize agents\n",
    "    research_agent = ResearchAgent(keywords=[\"AI\", \"technology\", \"machine learning\"])\n",
    "    answer_agent = AnswerDraftingAgent()\n",
    "    \n",
    "    # Step 1: Research Agent collects data\n",
    "    structured_data = research_agent.crawl_and_extract_data(\"AI technology news\")\n",
    "    \n",
    "    # Step 2: Answer Drafting Agent organizes data into knowledge graph\n",
    "    answer_agent.aggregate_data_into_graph(structured_data)\n",
    "    \n",
    "    # Step 3: Answer Drafting Agent generates a response to the query\n",
    "    query = \"What are the latest advancements in AI?\"\n",
    "    answer = answer_agent.generate_answer(query)\n",
    "    \n",
    "    print(answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
